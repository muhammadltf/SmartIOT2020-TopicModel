\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{url}
\usepackage{subfig}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Analysis on the Usage of Topic Model with Background Knowledge inside Discussion Activity in Industrial Engineering Context}

\author{\IEEEauthorblockN{Muhammad Luthfi\IEEEauthorrefmark{1}, Satoshi Goto\IEEEauthorrefmark{2}, Osamu Yoshie\IEEEauthorrefmark{3}}
\IEEEauthorblockA{\textit{Graduate School of Information, Production, and Systems} \\
\textit{Waseda University}\\
Kitakyushu, Japan \\
\IEEEauthorrefmark{1}muhammad.luthfi@akane.waseda.jp, \IEEEauthorrefmark{2}satoshi-goto@fuji.waseda.jp, \IEEEauthorrefmark{3}yoshie@waseda.jp}
}

\maketitle

\begin{abstract}
A better method to improve discussion activity is being actively investigated. To improve the consensus built inside discussion activity, some approaches has been proposed and we aimed to explore this possibility further. Previous proposals includes detecting non-verbal aspect to implicitly filter main ideas and proposing a new framework of short-term intensive workshop facilitated by a professional consultant in Product Lifecycle Management (PLM) process. In this paper, our goal is to analyse a digitized approach by performing topic modeling with the help of background knowledge on discussion activity held within industrial engineering context. We validate our findings to a professional consultant and conclude that our approach gives an adequate contribution  towards summarizing discussion activity in which, might improve consensus building process.
\end{abstract}

\begin{IEEEkeywords}
topic model, background knowledge, consensus building, product lifecycle management, data augmentation
\end{IEEEkeywords}

\section{Introduction}
A conventional discussion activity happened when a group of people let out their own opinion with appropriate feedbacks from the other. In industries, discussions are being held in various departments to solve specific problems. We can characterize such discussions as a group of people who shares a same interest aimed to build one single consensus. Furthermore, consensus building is important because it can resolves dispute more effectively by involving people from various levels and departments in an organization\cite{b1}. Nowadays, most companies are using consensus building approach on the requirement decision part of their products, hence making such activities as a specific-themed discussion activity. The practice of consensus building often times still have frequent problems. During discussion activities, various stakeholders with different personalities and backgrounds are present might influence final conclusion\cite{b2} which will affect tendency and direction of the discussion\cite{b3}.
 
Couple of methods can be implemented inside discussion activity to improve consensus quality such as recording, facilitation, and mediation\cite{b1}. Recording in this term stands for creating a physical record of what subject being discussed. Recording can be implemented by actually recording the whole discussion as a video file or even as simple as taking notes on participant's utterance. Facilitation in a second hand, help participants work together by providing artifact containing the discussion progress which everyone agrees on. Finally, mediation acts to help opposite parties deal with disagreement. In order to perform mediation, one independent person is needed to resolve disputes with his/her objective point of view.

Some researches has been conducted to improve consensus quality. One initiative takes form by performing implicit proposal (potential ideas) filtering utilizing non-verbal aspects of the discussion\cite{b5}. In digital transformation for smart, connected engineering field, another initiative has been proposed as a new framework of short term and intensive workshop facilitation for multi-party stakeholders in Product Lifecycle Management (PLM) strategy  planning phase \cite{b4}. Both initiatives tried to improve the overall discussion activity process while each of it has their own problems. The first initiative is not quite reliable since it depends heavily on participant's small gesture during discussion while the second one is heavily relied on one external professional consultant which might possibly produce biased judgment.

\section{Research Problem}
\label{sec_rp}
In this paper, we tried to resolve the disadvantages found in previous researches. We tried to propose a method to improve consensus quality that is reliable enough while also helping professional consultant against producing biased judgment. In simple terms, we conducted a digitized approach by analysing dialog data from discussion sessions and analyze it using topic model and background knowledge. We are utilizing dialog data from PLM-themed discussion activity to detect hidden pattern and latent opinion from participants. Then, we will validate our findings with a professional consultant to discover the method's effectiveness. However, a preliminary study regarding this matter has been conducted\cite{b3} and this research act as the extension of it with approval from the original author.

\section{Proposed Method}
In this research, we performed a digitized approach of dialog data from PLM-themed discussion activity sessions using data augmentation, topic model with background knowledge, and distribution similarity. First, the data will be prepared by a simple preprocess method and data augmentation. The clean and augmented data will then be experimented by various topic models and hyperparameters, we picked the best configuration and incorporate it into background-knowledge-backed topic model to generate topic distributions. Then, we will calculate the distribution similarity as convergence rate. Finally, a professional consultant will analyse the results to get an objective review. To summarize, we will take dialog data of discussion session and transform it into topic distributions, similarity value, and most frequent words (if necessary) from each discussion session to be validated by a professional consultant.

\subsection{Data Augmentation}
We took a real life dialog data from discussion sessions which ran for 1-2 hour long. Based on the dataset characteristics in Table~\ref{table 1: dataset characteristics}, the dataset we used is very poor. Thus, we are using data augmentation techniques to improve dataset quality. We expand the Easy Data Augmentation\cite{b7} by adding additional processes: hypernym replacement and hyponym replacement. Hypernym and hyponym of a word is crucial as we thought the topic mixture of a sentence {\it s} should be the same with other sentence {\it s'} who has hypernym/hyponym relation with some words inside it.

\subsection{Topic Model with Background Knowledge}
We tried to mine latent opinion of the dataset  using topic  model with background knowledge. Topic model is an unsupervised learning approach where we could transform documents into document-to-topic distributions and topic-to-word distributions. In topic model point of view, document is a mixture of topic where topic itself is a mixture of word. The most popular method of topic model is Latent Dirichlet Allocation (LDA)\cite{b8}, in which, most currently available topic model is proposed based on that. In LDA-based topic model, the learning process consists of generation process and sampling process. In generative process, the initial document-to-topic distributions and topic-to-word distributions are generated using hyperparameter $\alpha$ and $\beta$. Then, in the sampling process, distributions are evaluated by recalculating it using Gibbs Sampling for each and every word. The graphical notation of LDA topic model is shown in Fig.~\ref{fig_lda}, while the generation algorithm is:
\bigskip

\begin{algorithmic}[1]
\STATE For each topic {\it k} in {\it K}:
\begin{ALC@g} 
\STATE Generate $\phi_k$ \texttildelow{} Dir($\beta$) 
\end{ALC@g}
\STATE For each document {\it d} in {\it D}:
\begin{ALC@g} 
\STATE Generate $\theta_d$ \texttildelow{} Dir($\alpha$) 
\end{ALC@g}
\STATE For each position {\it i} of document {\it d} in {\it D}:
\begin{ALC@g} 
\STATE Generate $z_{id}$ \texttildelow{} Multinomial($\theta_d$)
\STATE Generate $w_{id}$ \texttildelow{} Multinomial($\phi_{z_{id}}$)
\end{ALC@g}
\end{algorithmic}
\bigskip

\begin{table}[h]
\caption{Dataset Characteristics}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Measures Type}&\textbf{PLM Workshop Dataset}&\textbf{Common Dataset \cite{b6}}\\
\hline
Total Documents&383&11094  \\
\hline
Corpus Size&686&4887 \\
\hline
Average Length&4.83&7.84 \\
\hline
\end{tabular}
\label{table 1: dataset characteristics}
\end{table}

\begin{figure}[h]
	\includegraphics[scale=0.5]{lda.png}
	\caption{LDA plate notation}
\label{fig_lda}
\end{figure}

\noindent where {\it K} is set of topics, {\it D} is set of documents, $\phi_k$ is topic-to-word distribution for topic {\it k}, $\theta_d$ is document-to-topic distribution for document {\it d}, $z_{id}$ is topic for the $i_{th}$ word in document {\it d}, and $w_{id}$ is the $i_{th}$ word in document {\it d}.

In our approach, we realize that our dataset has relatively smaller size compared to common topic model researches. Hence, we assembled various topic models with speciality in short text as suggested by\cite{b6}. The whole list of topic models could be seen in Table~\ref{table 2: topic model experiment}.

\begin{table}[b]
\caption{Topic Model Experiment}
\resizebox{0.5\textwidth}{!}{\begin{tabular}{|c|c|c|}
\hline
\textbf{No.}&\textbf{Topic Model}&\textbf{Type}\\
\hline
1&LDA\cite{b8}&Standard  \\
\hline
2&Dirichlet Multinomial Mixture (DMM)\cite{b11}&\multirow{5}{*}{\shortstack{One-topic \\sampling based}} \\
3&Latent-Feature LDA (LFLDA)\cite{b12}& \\
4&Latent-Feature DMM (LFDMM)\cite{b12}& \\
5&Generalized Polya Urn DMM (GPU-DMM)\cite{b13}& \\
6&GPU Poisson-based DMM (GPU-PDMM)\cite{b14}& \\
\hline
7&Biterm Topic Model (BTM)\cite{b15}&\multirow{2}{*}{\shortstack{Global word \\co-occurence based}} \\
8&Word Network Topic Model (WNTM)\cite{b16}& \\
\hline
9&Self-aggregate Topic Model (SATM)\cite{b17}&\multirow{2}{*}{\shortstack{Self-aggregation \\based}}\\
10&Pseudo-based Topic Model (PTM)\cite{b18}& \\
\hline
\end{tabular}}
\label{table 2: topic model experiment}
\end{table}

After the experiment is done we will decide what is the best topic model, hyperparameters, and the number of sentence augmentation processes to use. After that, we will incorporate the result to a new background-knowledge-backed topic model called Source-LDA\cite{b9} as the most suitable topic model for our case. In Source-LDA, we are able to provide background knowledge data to influence topic labeling thus improving topic quality in the process.

\subsection{Distribution Similarity}
In this step, we aimed to picture the topic distribution into a single value that describes the rate of consensus built (agreement rate). In order to do this, we used distribution similarity calculation using Jensen-Shannon Divergence across all distributions\cite{b10}. This concludes the final step of our proposed method.

\section{Experiment}
We had an opportunity to utilize dialog data from requirement decisions (discussion session) of 4 Japanese companies. Data preprocessing and sentence augmentation is done to clean the data. The comparison of dataset characteristics before and after augmentation is shown in Table~\ref{table 3: augmented dataset characteristics}. Furthermore, the property for each sentence in dataset is presented in Table~\ref{table 4: dataset property}.

Following the data preprocessing step, topic model experiment is conducted on all topic models in Table~\ref{table 2: topic model experiment}. We used {\it topic coherence} to evaluate topic model performance as our dataset is raw and golden label for each sentence is not present\cite{b6}. The result of topic model experiment is shown in Fig.~\ref{fig_tme} by averaging topic coherence value across various hyperparameters for each sentence augmentation processes. Most of the time, the usage of sentence augmentation process will improve topic coherence value.

From the result, we can conclude that 1 sentence augmentation processes gives the best and most consistent result compared to others.  Finally, we picked LDA topic model with $\alpha$ 0.15, $\beta$ 0.01, and 1 sentence augmentation process as the best configuration.

The next step is to incorporate this configuration into  Source-LDA. Based on our research problem from Section~\ref{sec_rp}, PLM topics is used as the background knowledge data. We decided to use PTC Value Roadmap\footnote{\url{http://support.ptc.com/WCMS/files/28837/en/J1051_ValueRoadmap_TS.pdf}} because it contains 26 PLM Topics with complete definitions for each topics. The background knowledge dataset held a relative big size consisting of 26 topics, 1068 unique words, and 145.88 average document length. Fig.~\ref{fig_tme2} shows the topic coherence value relative to the number of sentence augmentation process applied to background knowledge dataset.

Based on the result, we can conclude that the more we applied sentence augmentation on background knowledge, the better topic quality will be. In this experiment, the usage of background knowledge also improves the topic coherence value from 1.307 (LDA without background knowledge) to 1.311 (LDA with background knowledge).

\begin{table}[b]
\caption{Augmented Dataset Characteristics}
\resizebox{0.475\textwidth}{!}{\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Augmentation}&\textbf{Total Documents}&\textbf{Corpus Size}&\textbf{Average Length}\\
\hline
\begin{minipage}{0.1\textwidth}\center {\shortstack{No\\Augmentation}}\end{minipage}&383&686&4.83  \\
\hline
\begin{minipage}{0.1\textwidth}\center {\shortstack{1 Sentence \\Augmentation}}\end{minipage}&1017&922&5.00 \\
\hline
\begin{minipage}{0.1\textwidth}\center {\shortstack{9 Sentence \\Augmentation}}\end{minipage}&5085&1519&5.10 \\
\hline
\begin{minipage}{0.1\textwidth}\center {\shortstack{12 Sentence \\Augmentation}}\end{minipage}&6643&1681&5.10 \\
\hline
\end{tabular}}
\label{table 3: augmented dataset characteristics}
\end{table}

\begin{table}[b]
\caption{Dataset Property}
\resizebox{0.475\textwidth}{!}{\begin{tabular}{|c|c|}
\hline
\textbf{Property Name}&\textbf{Possible value}\\
\hline
Company ID&\{1,2,3,4\}  \\
\hline
Question Type&\{Problem, Solution\} \\
\hline
\begin{minipage}[b]{0.1\textwidth}\center Response Category\end{minipage}&{\shortstack{\{Information Technology, Corporate Management,\\Business Process, Human Development\}}} \\
\hline
Organization Level&\{very low, low, medium, high, very high\} \\
\hline
Opinion&\{short sentence consists around 5 words\} \\
\hline
\end{tabular}}
\label{table 4: dataset property}
\end{table}

\begin{figure}[b]
	\includegraphics[scale=0.425]{topic1.png}
	\caption{Topic coherence value based on topic model and sentence augmentation process performed on Dialog Data}
\label{fig_tme}
\end{figure}

\begin{figure}[t]
	\includegraphics[scale=0.425]{topic2.png}
	\caption{Topic coherence value based on background knowledge (BK) augmentation process}
\label{fig_tme2}
\end{figure}

\section{Results and Discussion}
In this section, the qualitative evaluation of the result will be presented. The average topic distribution from each company is shown in Fig.~\ref{fig_c}. In order to simplify the result, Table~\ref{table 5: mapping plm} shows the mapping value for each PLM topics. To simplify experiment process, the order of topic number is in alphabetical order and different with what shown in the reference i.e. PTC Value Roadmap. 

Topic distribution has finally obtained so we can proceed with similarity measurement using JS Divergence. All value approaching to 0 means that there is no variation between probability distributions, meanwhile value approaching to 1 means that there is high variation between probability distributions. The similarity of each discussion sessions can be seen at Table~\ref{table 6: similarity} along with the top frequent words. 

\begin{figure*}[t]
	\subfloat[Topic distributions for company 1]{\label{fig_c1}\includegraphics[scale=0.425]{company1.png}}
	\subfloat[Topic distributions for company 2]{\label{fig_c1}\includegraphics[scale=0.425]{company2.png}}\\
	\subfloat[Topic distributions for company 3]{\label{fig_c1}\includegraphics[scale=0.425]{company3.png}}
	\subfloat[Topic distributions for company 4]{\label{fig_c1}\includegraphics[scale=0.425]{company4.png}}
\caption{Average topic distributions of all company}
\label{fig_c}
\end{figure*}

Given the results, here is the feedback from professional consultant for each discussion session:

\paragraph{Company 1}{\it Company 1 had a key problem in terms of information exchange between design and manufacturing. I agree that the frequency of Design and Manufacturing topics was high. However, the topic of Project Management was rarely spoken directly by their voices. In addition, the analysis results show that there are few topics on Manufacturing Process Management. Certainly, there were few remarks on Manufacturing Process Management when the workshop was actually held. However, one of the participants was very concerned about the topic and he is one of the important people in the PLM project, so even if it is a minority opinions, I cannot ignore it as my consultant perspective. By the way, in the analysis results, the words with the highest frequency of occurrence were Information, Product, and Data. These were key words that participants often talked about during the actual workshop. As a consultant, I agree with that.}

\begin{table}[t]
\caption{Mapping of PLM Topics}
\resizebox{0.425\textwidth}{!}{\begin{tabular}{|c|c|}
\hline
\textbf{Mapping Value}&\textbf{PLM Topics}\\
\hline
Topic 0&Business System Support  \\
\hline
Topic 1&Change and Configuration Management \\
\hline
Topic 2&Component and Supplier Management \\
\hline
Topic 3&Concept Development \\
\hline
Topic 4&Design and Manufacturing Outsourcing \\
\hline
Topic 5&Equipment Monitoring and Lifecycle Management \\
\hline
Topic 6&Manufacturing Process Management \\
\hline
Topic 7&Mechanical, Electrical, and Software Development \\
\hline
Topic 8&Performance Analysis and Feedback \\
\hline
Topic 9&Platform Design and Variant Generation \\
\hline
Topic 10&Product Cost Management \\
\hline
Topic 11&Product Support Analysis and Planning \\
\hline
Topic 12&Project Management \\
\hline
Topic 13&Quality and Reliability Management \\
\hline
Topic 14&Regulatory and Materials Compliance \\
\hline
Topic 15&Requirements Definition and Management \\
\hline
Topic 16&Service Diagnostics and Knowledge Management \\
\hline
Topic 17&Service Logistics and Network Management \\
\hline
Topic 18&Service Order Management and Field Service \\
\hline
Topic 19&Service Parts Planning and Pricing \\
\hline
Topic 20&Smart, Connected Product Enablement \\
\hline
Topic 21&System Architecture Design \\
\hline
Topic 22&Technical and Service Parts Information Creation and Delivery\\
\hline
Topic 23&Tooling Design and Manufacture \\
\hline
Topic 24&Verification and Validation \\
\hline
Topic 25&Warranty and Performance-based Contract Management\\
\hline
\end{tabular}}
\label{table 5: mapping plm}
\end{table}

\begin{table}[t]
\caption{Similarity and Top Words}
\resizebox{0.425\textwidth}{!}{\begin{tabular}{|c|c|c|}
\hline
\textbf{Company ID}&\textbf{Similarity Rate}&\textbf{Top words}\\
\hline
Company 1&0.865&\{Information, Product, Data\}  \\
\hline
Company 2&0.766&\{Production, Work, Product\} \\
\hline
Company 3&0.672&\{Resource, Human, Product, Development\} \\
\hline
Company 4&0.753&\{Information, Data, Sharing\} \\
\hline
\end{tabular}}
\label{table 6: similarity}
\end{table}

\paragraph{Company 2}{\it The company 2 had three business unit. Thus, the participants had different opinions, as each business unit had a completely different product and each business model was different. When I looked at the results of this analysis, I thought that the reason that the topic of Verification and Validation was high was probably that they had a problem with their product quality. However, although the topic about Field Service has not been talked about in the actual workshop time, the frequency of topic 18 was high in this analysis result. In fact, this company does little field service work, so it is necessary to confirm why such analysis results were performed. In addition, the analysis results indicated that the frequency of Product Cost Management and Project Management topics was low. However, I think the discussions about costs and projects were relatively common during the actual discussions with them. Regarding the word distribution, the analysis result, it showed that the frequency of Production, Work, and Product were high. I agree with this result.}

\paragraph{Company 3}{\it The motivation for Company 3 to introduce PLM was to strengthen its field service operations. Looking at the analysis results, it was found that the topics with the highest frequency were field services, such as Warranty management, Performance Based Contract Management, Technical Service Parts Information, and Service Order Management. I agree this result as a professional consultant. However, regarding the monitoring and management of equipment, it was analyzed that the topic frequency was low. This is different from the actual situation, because in the actual workshop, the story of equipment monitoring was relatively well discussed. The frequency of words of Resource, Human, Product, and Development is high. Even during the actual workshop discussion, the shortage of human resources in field service was very problematic. Thus, I agree with the analysis results.}

\paragraph{Company 4}{\it Company 4 has been practicing efforts to make its factory a smart factory. As a consultant, what I noticed in their actual workshops was their lack of information sharing between departments and insufficient training of employees. On the other hand, looking at the results of this analysis, we found that the topic \# 22 was Technical and Service Part Information Creation and Delivery. At first, I wasn't interested in topic \# 22. However, after reviewing the content of discussions with the workshop participants at a later date, there was an opinion that attention was paid to the management of service parts in order to contribute to sustainable sales. It seems that the results of this analysis have taught me a topic that I did not notice at first. Looking at the analysis results of the word distribution, it seems that three words, Information, Data, and Sharing, appear frequently. This was exactly the issue that was being talked about at the workshop. Additionally, The analysis results seem to indicate that there is no relationship between education and system design. Further investigation is needed as I think education topic should be highly related in the workshop.}
\bigskip

Based on our analysis and feedback from professional consultant. We feel that our experiment on the usage of topic model with background knowledge in a industrial engineering discussion activity (in this case, PLM-themed) gives an actual contribution towards discussion overview in which, might improve consensus building process. The important takeaway of this  research is that topic modeling with background knowledge will assist professional consultant to understand more towards participant's latent opinion.

\section{Conclusion and Future Works}
In this paper, we proposed digitized approach to improve consensus building process in discussion activity held within industrial engineering context (PLM-themed). Our proposed method consists of performing data augmentation, implementing topic model with background knowledge, and calculating the distribution similarity. Finally, we validate the result on professional consultant. We received a relatively good feedback about this which validate our purpose of using a new approach to improve consensus building process.

However, further approach is still necessary based on two perspective: consensus building and topic modeling. From consensus building perspective, we still need to assure the emotional state of discussion participants when dialog data is recorded. Some variables might aspect the quality and consistency of participant's opinion. Meanwhile from topic modeling perspective, we are planning to expand Source-LDA so it can afford different data representation like BTM and WNTM does.

\begin{thebibliography}{00}
\bibitem{b1} J. Thomas-Lamar, S. Mckearnan, and L. Susskind, ``The Consensus Building Handbook: A Comprehensive Guide to Reaching Agreement'', SAGE Publications, 1999. pp.7--9.
\bibitem{b2} N. He, S. Yao, and O.Yoshie, ``Emotional speech classification in consensus building'', {\it 2014 10th International Conference on Communications (COMM)}, Bucharest, 2014, pp. 1-4.
\bibitem{b3} S. Goto, O. Yoshie, and S.Fujimura, ``Preliminary Study: Text mining approach to dialog data of stakeholders on requirement decision for Enterprise Information System'', {\it 2019 10th Annual European Decision Sciences Institute (EDSI) Conference}, Nottingham, 2019.
\bibitem{b4} S. Goto, O. Yoshie, and S. Fujimura, ``Empirical study of multi-party workshop facilitation in strategy planning phase for Product Lifecycle Management (PLM) system'', {\it 2019 International Federation for Information Processing (IFIP) International Conference on Product Lifecycle Management}, Moscow, 2019, pp. 82-93.
\bibitem{b5} Y. Katagiri et al., ``Implicit proposal filtering in multi-party consensus-building conversations'', {\it Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue}, Columbus, 2008, pp.100-103.
\bibitem{b6} J. Qiang, Z. Qian, Y. Li, Y. Yuan, and X. Wu, ``Short text topic modeling techniques, applications, and performance: a survey'', 2019.
\bibitem{b7} J. Wei and K. Zou, ``EDA: Easy Data Augmentation techniques for boosting performance on text classification tasks'', {\it Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, Hong Kong, 2019, pp. 6383-6389.
\bibitem{b8} D.M. Blei, A.Y. Ng, and M.I. Jordan, ``Latent Dirichlet Allocation'', {\it Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic}, Vancouver, 2001, pp.601-608.
\bibitem{b9} J. Wood, P. Tan, W. Wang, and C. Arnold, ``Source-LDA: Enhancing probabilistic topic models using prior knowledge sources'', {\it 33rd IEEE International Conference on Data Engineering (ICDE)}, San Diego, 2017, pp. 411-422. 
\bibitem{b10} J.A. Aslam and V. Pavlu, ``Query hardness estimation using Jensen-Shannon Divergence among multiple scoring functions'', {\it 29th European Conference on Information Retrieval Research (ECIR)}, Rome, 2007, pp. 198-209.
\bibitem{b11} J. Yin and J. Wang, ``A dirichlet multinomial mixture model-based approach for short text clustering'', {\it Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, New York,2014, pp. 233-242.
\bibitem{b12} D.Q. Nyugen, R. Billingsley, L. Du, and M. Johnson, ``Improving topic models with latent feature word representations'', {\it Transactions of the Association for Computational Linguistics vol. 3}, 2015, pp. 299-313.
\bibitem{b13} C. Li et al., ``Topic modeling for short texts with auxiliary word embeddings'', {\it Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval}, Pisa, 2016, pp. 165-174.
\bibitem{b14} C. Li et al., ``Enhancing topic modeling for short texts with auxiliary word embeddings'', {\it ACM Transactions on Information Systems (TOIS)}, 2017, pp. 1-30.
\bibitem{b15} X. Cheng, X. Yan, Y. Lan, and J. Guo, ``Btm: Topic modeling over short texts'', {\it IEEE Transactions on Knowledge and Data Engineering}, 2014, pp. 2928-2941.
\bibitem{b16} Y. Zuo, J. Zhao, and K. Xu, ``Word network topic model: a simple but general solution for short and imbalanced texts'', {\it Knowledge and Information Systems}, 2016, pp.  379-398.
\bibitem{b17} X. Quan, C. Kit, Y. Ge, and S.J. Pan, ``Short and sparse text topic modeling via self-aggregation'', {\it Proceedings of the 24th International Conference on Artificial Intelligence}, Buenos Aires, 2015, pp. 2270-2276.
\bibitem{b18} Y. Zuo et al., ``Topic modeling of short texts: A pseudo-document view'', {\it Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining}, San Fransisco, 2016, pp.2105-2114.
\bibitem{b19} K. Ondrej and J. Marlin, ``Product life cycle in digital factory,'' {\it Knowledge management and innovation: a business competitive edge perspective}, Cairo, 2010, pp. 1881-1886.  
\end{thebibliography}

\appendix[Preliminary Experiment]
\label{appendix_1}
\noindent We conduct a preliminary experiment to prove the effectiveness of our method. The dialog data we used is an original data with very limited context and small corpus size. Hence, we would like to validate our method by experimenting it on a widely-used dataset. We performed data augmentation processes on Biomedical dataset taken from\cite{b6} which has 20 topics, 4498 corpus, 19448 documents, and 7.44 average document length. Then, we perform topic modeling using LDA, BTM, and PTM algorithm. Finally, we evaluate it by calculating their {\it topic coherence} value. After our preliminary experiment is finished, Fig.~\ref{fig_tmv} shows that data augmentation will improve topic quality on a certain degree.

\begin{figure} [b]
	\includegraphics[scale=0.425]{topic3.png}
	\caption{Topic coherence value based on topic model and sentence augmentation process performed on Biomedical Dataset}
\label{fig_tmv}
\end{figure}

\end{document}
